
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; PyStocks</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      <h1 class="site-logo" id="site-title">PyStocks</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   PyStocks
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  FB Prophet
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AAPL.html">
   (AAPL): Apple Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MSFT.html">
   (MSFT): Microsoft Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AMZN.html">
   (AMZN): Amazon.com Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/GOOG.html">
   (GOOG): Alphabet Inc. Class C Capital Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/GOOGL.html">
   (GOOGL): Alphabet Inc. Class A Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/FB.html">
   (FB): Facebook Inc. Class A Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TSM.html">
   (TSM): Taiwan Semiconductor Manufacturing Company Ltd.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TSLA.html">
   (TSLA): Tesla Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BABA.html">
   (BABA): Alibaba Group Holding Limited American Depositary Shares each representing eight Ordinary share
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/JPM.html">
   (JPM): JP Morgan Chase &amp; Co. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/V.html">
   (V): Visa Inc.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/JNJ.html">
   (JNJ): Johnson &amp; Johnson Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NVDA.html">
   (NVDA): NVIDIA Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/WMT.html">
   (WMT): Walmart Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/UNH.html">
   (UNH): UnitedHealth Group Incorporated Common Stock (DE)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BAC.html">
   (BAC): Bank of America Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MA.html">
   (MA): Mastercard Incorporated Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/HD.html">
   (HD): Home Depot Inc. (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PG.html">
   (PG): Procter &amp; Gamble Company (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/DIS.html">
   (DIS): Walt Disney Company (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PYPL.html">
   (PYPL): PayPal Holdings Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ASML.html">
   (ASML): ASML Holding N.V. New York Registry Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CMCSA.html">
   (CMCSA): Comcast Corporation Class A Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/XOM.html">
   (XOM): Exxon Mobil Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ADBE.html">
   (ADBE): Adobe Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/KO.html">
   (KO): Coca-Cola Company (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TM.html">
   (TM): Toyota Motor Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/INTC.html">
   (INTC): Intel Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ORCL.html">
   (ORCL): Oracle Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CSCO.html">
   (CSCO): Cisco Systems Inc. Common Stock (DE)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NFLX.html">
   (NFLX): Netflix Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CRM.html">
   (CRM): Salesforce.com Inc Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PFE.html">
   (PFE): Pfizer Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NKE.html">
   (NKE): Nike Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/T.html">
   (T): AT&amp;T Inc.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ABT.html">
   (ABT): Abbott Laboratories Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PEP.html">
   (PEP): PepsiCo Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CVX.html">
   (CVX): Chevron Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ABBV.html">
   (ABBV): AbbVie Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NVS.html">
   (NVS): Novartis AG Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/WFC.html">
   (WFC): Wells Fargo &amp; Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AVGO.html">
   (AVGO): Broadcom Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MRK.html">
   (MRK): Merck &amp; Company Inc. Common Stock (new)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/LLY.html">
   (LLY): Eli Lilly and Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BHP.html">
   (BHP): BHP Group Limited American Depositary Shares (Each representing two Ordinary Shares)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/UPS.html">
   (UPS): United Parcel Service Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TMO.html">
   (TMO): Thermo Fisher Scientific Inc Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/DHR.html">
   (DHR): Danaher Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NVO.html">
   (NVO): Novo Nordisk A/S Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/ACN.html">
   (ACN): Accenture plc Class A Ordinary Shares (Ireland)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TMUS.html">
   (TMUS): T-Mobile US Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TXN.html">
   (TXN): Texas Instruments Incorporated Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MCD.html">
   (MCD): McDonald’s Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/EDU.html">
   (EDU): New Oriental Education &amp; Technology Group Inc. Sponsored ADR representing 1 Ordinary Share (Cayman Islands)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MDT.html">
   (MDT): Medtronic plc. Ordinary Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MS.html">
   (MS): Morgan Stanley Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/COST.html">
   (COST): Costco Wholesale Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SAP.html">
   (SAP): SAP  SE ADS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/C.html">
   (C): Citigroup Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/HON.html">
   (HON): Honeywell International Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/UL.html">
   (UL): Unilever PLC Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PDD.html">
   (PDD): Pinduoduo Inc. American Depositary Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/LIN.html">
   (LIN): Linde plc Ordinary Share
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SHOP.html">
   (SHOP): Shopify Inc. Class A Subordinate Voting Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BBL.html">
   (BBL): BHP Group PlcSponsored ADR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/QCOM.html">
   (QCOM): QUALCOMM Incorporated Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/PM.html">
   (PM): Philip Morris International Inc Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BUD.html">
   (BUD): Anheuser-Busch Inbev SA Sponsored ADR (Belgium)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/UNP.html">
   (UNP): Union Pacific Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AZN.html">
   (AZN): AstraZeneca PLC American Depositary Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/RY.html">
   (RY): Royal Bank Of Canada Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BMY.html">
   (BMY): Bristol-Myers Squibb Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BA.html">
   (BA): Boeing Company (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/NEE.html">
   (NEE): NextEra Energy Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CHTR.html">
   (CHTR): Charter Communications Inc. Class A Common Stock New
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/RIO.html">
   (RIO): Rio Tinto Plc Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/HDB.html">
   (HDB): HDFC Bank Limited Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SCHW.html">
   (SCHW): Charles Schwab Corporation (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/LOW.html">
   (LOW): Lowe’s Companies Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AMGN.html">
   (AMGN): Amgen Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/RTX.html">
   (RTX): Raytheon Technologies Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SBUX.html">
   (SBUX): Starbucks Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/BLK.html">
   (BLK): BlackRock Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SNY.html">
   (SNY): Sanofi ADR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SE.html">
   (SE): Sea Limited American Depositary Shares each representing one Class A Ordinary Share
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/HSBC.html">
   (HSBC): HSBC Holdings plc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CAT.html">
   (CAT): Caterpillar Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TD.html">
   (TD): Toronto Dominion Bank (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AXP.html">
   (AXP): American Express Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/IBM.html">
   (IBM): International Business Machines Corporation Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/GS.html">
   (GS): Goldman Sachs Group Inc. (The) Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AMAT.html">
   (AMAT): Applied Materials Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/CSAN.html">
   (CSAN): Cosan S.A. ADS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/SONY.html">
   (SONY): Sony Group Corporation American Depositary Shares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/GE.html">
   (GE): General Electric Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/TOT.html">
   (TOT): Total SE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/INTU.html">
   (INTU): Intuit Inc. Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/MMM.html">
   (MMM): 3M Company Common Stock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fbprophet/AMT.html">
   (AMT): American Tower Corporation (REIT) Common Stock
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/pystocks/stocks/methods/StockPredTest.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ckrusemd/pystocks/master?urlpath=tree/pystocks/stocks/methods/StockPredTest.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>If you want to use google drive for storage and retrieval please uncomment the below code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#from google.colab import drive</span>
<span class="c1">#drive.mount(&#39;/gdrive&#39;)</span>
<span class="c1">#%cd /gdrive</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install <span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.0.0-beta0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">ERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0-beta0 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0)</span>
<span class=" -Color -Color-Red">ERROR: No matching distribution found for tensorflow==2.0.0-beta0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span> 
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">06539752</span><span class="n">a07f</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;tensorflow&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.initializers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.layers</span> <span class="kn">import</span> <span class="n">Layer</span>


<span class="k">class</span> <span class="nc">LayerNormalization</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LayerNormalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span>
                                     <span class="n">initializer</span><span class="o">=</span><span class="n">Ones</span><span class="p">(),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span>
                                    <span class="n">initializer</span><span class="o">=</span><span class="n">Zeros</span><span class="p">(),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LayerNormalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_shape</span>

<span class="k">class</span> <span class="nc">ScaledDotProductAttention</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">attn_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">attn_dropout</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">batch_dot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">temper</span><span class="p">)([</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mmask</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:(</span><span class="o">-</span><span class="mf">1e+10</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">))(</span><span class="n">mask</span><span class="p">)</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">attn</span><span class="p">,</span> <span class="n">mmask</span><span class="p">])</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">attn</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">batch_dot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))([</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn</span>

<span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">():</span>
    <span class="c1"># mode 0 - big martixes, faster; mode 1 - more clear implementation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_k</span><span class="p">,</span> <span class="n">d_v</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span> <span class="o">=</span> <span class="n">n_head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_v</span> <span class="o">=</span> <span class="n">d_v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qs_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_head</span><span class="o">*</span><span class="n">d_k</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ks_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_head</span><span class="o">*</span><span class="n">d_k</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vs_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_head</span><span class="o">*</span><span class="n">d_v</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qs_layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ks_layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vs_layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_head</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">qs_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_k</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ks_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_k</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vs_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_v</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">ScaledDotProductAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_norm</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_o</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d_k</span><span class="p">,</span> <span class="n">d_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_v</span>
        <span class="n">n_head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">qs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qs_layer</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># [batch_size, len_q, n_head*d_k]</span>
            <span class="n">ks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ks_layer</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="n">vs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vs_layer</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">reshape1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># [batch_size, len_q, n_head * d_k]</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">d_k</span><span class="p">])</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">d_k</span><span class="p">])</span>  <span class="c1"># [n_head * batch_size, len_q, d_k]</span>
                <span class="k">return</span> <span class="n">x</span>
            <span class="n">qs</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">reshape1</span><span class="p">)(</span><span class="n">qs</span><span class="p">)</span>
            <span class="n">ks</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">reshape1</span><span class="p">)(</span><span class="n">ks</span><span class="p">)</span>
            <span class="n">vs</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">reshape1</span><span class="p">)(</span><span class="n">vs</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">repeat_elements</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">mask</span><span class="p">)</span>
            <span class="n">head</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">vs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>  
                
            <span class="k">def</span> <span class="nf">reshape2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># [n_head * batch_size, len_v, d_v]</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">n_head</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span> 
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_head</span><span class="o">*</span><span class="n">d_v</span><span class="p">])</span>  <span class="c1"># [batch_size, len_v, n_head * d_v]</span>
                <span class="k">return</span> <span class="n">x</span>
            <span class="n">head</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">reshape2</span><span class="p">)(</span><span class="n">head</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">attns</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_head</span><span class="p">):</span>
                <span class="n">qs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qs_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">q</span><span class="p">)</span>   
                <span class="n">ks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ks_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">k</span><span class="p">)</span> 
                <span class="n">vs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vs_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">v</span><span class="p">)</span> 
                <span class="n">head</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">vs</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
                <span class="n">heads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">head</span><span class="p">);</span> <span class="n">attns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
            <span class="n">head</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()(</span><span class="n">heads</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_head</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">heads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">()(</span><span class="n">attns</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_head</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">attns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_o</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">:</span> <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">attn</span>
        <span class="c1"># outputs = Add()([outputs, q]) # sl: fix</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">outputs</span><span class="p">),</span> <span class="n">attn</span>

<span class="k">class</span> <span class="nc">PositionwiseFeedForward</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_hid</span><span class="p">,</span> <span class="n">d_inner_hid</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">d_inner_hid</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">d_hid</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_2</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">output</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner_hid</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">d_k</span><span class="p">,</span> <span class="n">d_v</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_att_layer</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">n_head</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_k</span><span class="p">,</span> <span class="n">d_v</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_ffn_layer</span>  <span class="o">=</span> <span class="n">PositionwiseFeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner_hid</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_input</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">slf_attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_att_layer</span><span class="p">(</span><span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_input</span><span class="p">,</span> <span class="n">enc_input</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_ffn_layer</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">slf_attn</span>


<span class="k">def</span> <span class="nf">GetPosEncodingMatrix</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_emb</span><span class="p">):</span>
    <span class="n">pos_enc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="n">pos</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">j</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d_emb</span><span class="p">)]</span> 
        <span class="k">if</span> <span class="n">pos</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d_emb</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
            <span class="p">])</span>
    <span class="n">pos_enc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos_enc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># dim 2i</span>
    <span class="n">pos_enc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos_enc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># dim 2i+1</span>
    <span class="k">return</span> <span class="n">pos_enc</span>


<span class="k">def</span> <span class="nf">GetPadMask</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">batch_dot</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">mask</span>


<span class="k">def</span> <span class="nf">GetSubMask</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">len_s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">s</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">s</span><span class="p">)[:</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">len_s</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">bs</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mask</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">4</span><span class="o">-</span><span class="n">ba2cfa3691b3</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="o">*</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;tensorflow&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomeLearningSchedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomeLearningSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">param_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
        <span class="n">param_2</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">param_1</span><span class="p">,</span> <span class="n">param_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">5</span><span class="o">-</span><span class="n">b8a52ab15322</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="k">class</span> <span class="nc">CustomeLearningSchedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>         <span class="nb">super</span><span class="p">(</span><span class="n">CustomeLearningSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>         <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>         <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>

<span class="ne">NameError</span>: name &#39;tf&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_learning_rate</span> <span class="o">=</span> <span class="n">CustomeLearningSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sample_learning_rate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">200000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Train Step&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">6</span><span class="o">-</span><span class="mi">5</span><span class="n">b4a8ff86da4</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">sample_learning_rate</span> <span class="o">=</span> <span class="n">CustomeLearningSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sample_learning_rate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">200000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Train Step&quot;</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;CustomeLearningSchedule&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D_MODEL</span><span class="o">=</span><span class="mi">300</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">CustomeLearningSchedule</span><span class="p">(</span><span class="n">D_MODEL</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                                     <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                                     <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>
                                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">7</span><span class="o">-</span><span class="mi">09</span><span class="n">d964857cd1</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">D_MODEL</span><span class="o">=</span><span class="mi">300</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">CustomeLearningSchedule</span><span class="p">(</span><span class="n">D_MODEL</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>

<span class="ne">NameError</span>: name &#39;CustomeLearningSchedule&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEQ_LEN</span><span class="o">=</span><span class="mi">60</span>
<span class="k">def</span> <span class="nf">build_model</span><span class="p">():</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))(</span><span class="n">inp</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span> 
        
    <span class="c1">#for i in range(2):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">self_attn</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">D_MODEL</span><span class="p">,</span>
            <span class="n">d_inner_hid</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
            <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
            <span class="n">d_k</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">d_v</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        
    <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">GlobalAveragePooling1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">max_pool</span> <span class="o">=</span> <span class="n">GlobalMaxPooling1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">conc</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">avg_pool</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">])</span>
    <span class="n">conc</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">conc</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">conc</span><span class="p">)</span>      

    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span>  
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">multi_head</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
<span class="n">multi_head</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">9</span><span class="o">-</span><span class="mi">3</span><span class="n">ac7ebf451fa</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">multi_head</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">multi_head</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="nn">&lt;ipython-input-8-3e9d4aa04043&gt;</span> in <span class="ni">build_model</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">SEQ_LEN</span><span class="o">=</span><span class="mi">60</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="k">def</span> <span class="nf">build_model</span><span class="p">():</span>
<span class="ne">----&gt; </span><span class="mi">3</span>     <span class="n">inp</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">SEQ_LEN</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))(</span><span class="n">inp</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;Input&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace with the location where checkpoint exists</span>

<span class="n">multi_head</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;./checkpoints/final_checkpoint_1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">23</span><span class="n">fc0bae2a71</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Replace with the location where checkpoint exists</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">multi_head</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;./checkpoints/final_checkpoint_1&#39;</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;multi_head&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install alpha_vantage
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting alpha_vantage
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting aiohttp
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading aiohttp-3.7.4.post0-cp38-cp38-manylinux2014_x86_64.whl (1.5 MB)
?25l
     |▎                               | 10 kB 41.4 MB/s eta 0:00:01
     |▌                               | 20 kB 47.9 MB/s eta 0:00:01
     |▊                               | 30 kB 48.4 MB/s eta 0:00:01
     |█                               | 40 kB 26.1 MB/s eta 0:00:01
     |█▏                              | 51 kB 20.4 MB/s eta 0:00:01
     |█▍                              | 61 kB 18.1 MB/s eta 0:00:01
     |█▋                              | 71 kB 11.1 MB/s eta 0:00:01
     |█▉                              | 81 kB 12.3 MB/s eta 0:00:01
     |██                              | 92 kB 12.4 MB/s eta 0:00:01
     |██▎                             | 102 kB 13.5 MB/s eta 0:00:01
     |██▌                             | 112 kB 13.5 MB/s eta 0:00:01
     |██▊                             | 122 kB 13.5 MB/s eta 0:00:01
     |███                             | 133 kB 13.5 MB/s eta 0:00:01
     |███▏                            | 143 kB 13.5 MB/s eta 0:00:01
     |███▍                            | 153 kB 13.5 MB/s eta 0:00:01
     |███▋                            | 163 kB 13.5 MB/s eta 0:00:01
     |███▉                            | 174 kB 13.5 MB/s eta 0:00:01
     |████                            | 184 kB 13.5 MB/s eta 0:00:01
     |████▎                           | 194 kB 13.5 MB/s eta 0:00:01
     |████▌                           | 204 kB 13.5 MB/s eta 0:00:01
     |████▊                           | 215 kB 13.5 MB/s eta 0:00:01
     |█████                           | 225 kB 13.5 MB/s eta 0:00:01
     |█████▏                          | 235 kB 13.5 MB/s eta 0:00:01
     |█████▍                          | 245 kB 13.5 MB/s eta 0:00:01
     |█████▋                          | 256 kB 13.5 MB/s eta 0:00:01
     |█████▉                          | 266 kB 13.5 MB/s eta 0:00:01
     |██████                          | 276 kB 13.5 MB/s eta 0:00:01
     |██████▎                         | 286 kB 13.5 MB/s eta 0:00:01
     |██████▌                         | 296 kB 13.5 MB/s eta 0:00:01
     |██████▊                         | 307 kB 13.5 MB/s eta 0:00:01
     |███████                         | 317 kB 13.5 MB/s eta 0:00:01
     |███████▏                        | 327 kB 13.5 MB/s eta 0:00:01
     |███████▍                        | 337 kB 13.5 MB/s eta 0:00:01
     |███████▋                        | 348 kB 13.5 MB/s eta 0:00:01
     |███████▉                        | 358 kB 13.5 MB/s eta 0:00:01
     |████████                        | 368 kB 13.5 MB/s eta 0:00:01
     |████████▎                       | 378 kB 13.5 MB/s eta 0:00:01
     |████████▌                       | 389 kB 13.5 MB/s eta 0:00:01
     |████████▊                       | 399 kB 13.5 MB/s eta 0:00:01
     |█████████                       | 409 kB 13.5 MB/s eta 0:00:01
     |█████████▏                      | 419 kB 13.5 MB/s eta 0:00:01
     |█████████▍                      | 430 kB 13.5 MB/s eta 0:00:01
     |█████████▋                      | 440 kB 13.5 MB/s eta 0:00:01
     |█████████▉                      | 450 kB 13.5 MB/s eta 0:00:01
     |██████████                      | 460 kB 13.5 MB/s eta 0:00:01
     |██████████▎                     | 471 kB 13.5 MB/s eta 0:00:01
     |██████████▌                     | 481 kB 13.5 MB/s eta 0:00:01
     |██████████▊                     | 491 kB 13.5 MB/s eta 0:00:01
     |███████████                     | 501 kB 13.5 MB/s eta 0:00:01
     |███████████▏                    | 512 kB 13.5 MB/s eta 0:00:01
     |███████████▍                    | 522 kB 13.5 MB/s eta 0:00:01
     |███████████▋                    | 532 kB 13.5 MB/s eta 0:00:01
     |███████████▉                    | 542 kB 13.5 MB/s eta 0:00:01
     |████████████                    | 552 kB 13.5 MB/s eta 0:00:01
     |████████████▎                   | 563 kB 13.5 MB/s eta 0:00:01
     |████████████▌                   | 573 kB 13.5 MB/s eta 0:00:01
     |████████████▊                   | 583 kB 13.5 MB/s eta 0:00:01
     |█████████████                   | 593 kB 13.5 MB/s eta 0:00:01
     |█████████████▏                  | 604 kB 13.5 MB/s eta 0:00:01
     |█████████████▍                  | 614 kB 13.5 MB/s eta 0:00:01
     |█████████████▋                  | 624 kB 13.5 MB/s eta 0:00:01
     |█████████████▉                  | 634 kB 13.5 MB/s eta 0:00:01
     |██████████████                  | 645 kB 13.5 MB/s eta 0:00:01
     |██████████████▎                 | 655 kB 13.5 MB/s eta 0:00:01
     |██████████████▌                 | 665 kB 13.5 MB/s eta 0:00:01
     |██████████████▊                 | 675 kB 13.5 MB/s eta 0:00:01
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     |███████████████                 | 686 kB 13.5 MB/s eta 0:00:01
     |███████████████▏                | 696 kB 13.5 MB/s eta 0:00:01
     |███████████████▍                | 706 kB 13.5 MB/s eta 0:00:01
     |███████████████▊                | 716 kB 13.5 MB/s eta 0:00:01
     |████████████████                | 727 kB 13.5 MB/s eta 0:00:01
     |████████████████▏               | 737 kB 13.5 MB/s eta 0:00:01
     |████████████████▍               | 747 kB 13.5 MB/s eta 0:00:01
     |████████████████▋               | 757 kB 13.5 MB/s eta 0:00:01
     |████████████████▉               | 768 kB 13.5 MB/s eta 0:00:01
     |█████████████████               | 778 kB 13.5 MB/s eta 0:00:01
     |█████████████████▎              | 788 kB 13.5 MB/s eta 0:00:01
     |█████████████████▌              | 798 kB 13.5 MB/s eta 0:00:01
     |█████████████████▊              | 808 kB 13.5 MB/s eta 0:00:01
     |██████████████████              | 819 kB 13.5 MB/s eta 0:00:01
     |██████████████████▏             | 829 kB 13.5 MB/s eta 0:00:01
     |██████████████████▍             | 839 kB 13.5 MB/s eta 0:00:01
     |██████████████████▋             | 849 kB 13.5 MB/s eta 0:00:01
     |██████████████████▉             | 860 kB 13.5 MB/s eta 0:00:01
     |███████████████████             | 870 kB 13.5 MB/s eta 0:00:01
     |███████████████████▎            | 880 kB 13.5 MB/s eta 0:00:01
     |███████████████████▌            | 890 kB 13.5 MB/s eta 0:00:01
     |███████████████████▊            | 901 kB 13.5 MB/s eta 0:00:01
     |████████████████████            | 911 kB 13.5 MB/s eta 0:00:01
     |████████████████████▏           | 921 kB 13.5 MB/s eta 0:00:01
     |████████████████████▍           | 931 kB 13.5 MB/s eta 0:00:01
     |████████████████████▋           | 942 kB 13.5 MB/s eta 0:00:01
     |████████████████████▉           | 952 kB 13.5 MB/s eta 0:00:01
     |█████████████████████           | 962 kB 13.5 MB/s eta 0:00:01
     |█████████████████████▎          | 972 kB 13.5 MB/s eta 0:00:01
     |█████████████████████▌          | 983 kB 13.5 MB/s eta 0:00:01
     |█████████████████████▊          | 993 kB 13.5 MB/s eta 0:00:01
     |██████████████████████          | 1.0 MB 13.5 MB/s eta 0:00:01
     |██████████████████████▏         | 1.0 MB 13.5 MB/s eta 0:00:01
     |██████████████████████▍         | 1.0 MB 13.5 MB/s eta 0:00:01
     |██████████████████████▋         | 1.0 MB 13.5 MB/s eta 0:00:01
     |██████████████████████▉         | 1.0 MB 13.5 MB/s eta 0:00:01
     |███████████████████████         | 1.1 MB 13.5 MB/s eta 0:00:01
     |███████████████████████▎        | 1.1 MB 13.5 MB/s eta 0:00:01
     |███████████████████████▌        | 1.1 MB 13.5 MB/s eta 0:00:01
     |███████████████████████▊        | 1.1 MB 13.5 MB/s eta 0:00:01
     |████████████████████████        | 1.1 MB 13.5 MB/s eta 0:00:01
     |████████████████████████▏       | 1.1 MB 13.5 MB/s eta 0:00:01
     |████████████████████████▍       | 1.1 MB 13.5 MB/s eta 0:00:01
     |████████████████████████▋       | 1.1 MB 13.5 MB/s eta 0:00:01
     |████████████████████████▉       | 1.1 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████       | 1.1 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████▎      | 1.2 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████▌      | 1.2 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████▊      | 1.2 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████      | 1.2 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████▏     | 1.2 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████▍     | 1.2 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████▋     | 1.2 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████▉     | 1.2 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████     | 1.2 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████▎    | 1.2 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████▌    | 1.3 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████▊    | 1.3 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████    | 1.3 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████▏   | 1.3 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████▍   | 1.3 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████▋   | 1.3 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████▉   | 1.3 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████████   | 1.3 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████████▎  | 1.3 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████████▌  | 1.4 MB 13.5 MB/s eta 0:00:01
     |█████████████████████████████▊  | 1.4 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████████  | 1.4 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████████▏ | 1.4 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████████▍ | 1.4 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████████▋ | 1.4 MB 13.5 MB/s eta 0:00:01
     |██████████████████████████████▉ | 1.4 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████████ | 1.4 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████████▍| 1.4 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████████▋| 1.4 MB 13.5 MB/s eta 0:00:01
     |███████████████████████████████▉| 1.5 MB 13.5 MB/s eta 0:00:01
     |████████████████████████████████| 1.5 MB 13.5 MB/s 
?25hRequirement already satisfied: requests in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from alpha_vantage) (2.25.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting multidict&lt;7.0,&gt;=4.5
  Downloading multidict-5.1.0-cp38-cp38-manylinux2014_x86_64.whl (159 kB)
?25l
     |██                              | 10 kB 42.9 MB/s eta 0:00:01
     |████▏                           | 20 kB 47.0 MB/s eta 0:00:01
     |██████▏                         | 30 kB 57.3 MB/s eta 0:00:01
     |████████▎                       | 40 kB 65.1 MB/s eta 0:00:01
     |██████████▎                     | 51 kB 70.7 MB/s eta 0:00:01
     |████████████▍                   | 61 kB 76.7 MB/s eta 0:00:01
     |██████████████▍                 | 71 kB 80.8 MB/s eta 0:00:01
     |████████████████▌               | 81 kB 84.6 MB/s eta 0:00:01
     |██████████████████▌             | 92 kB 74.4 MB/s eta 0:00:01
     |████████████████████▋           | 102 kB 73.6 MB/s eta 0:00:01
     |██████████████████████▋         | 112 kB 73.6 MB/s eta 0:00:01
     |████████████████████████▊       | 122 kB 73.6 MB/s eta 0:00:01
     |██████████████████████████▊     | 133 kB 73.6 MB/s eta 0:00:01
     |████████████████████████████▉   | 143 kB 73.6 MB/s eta 0:00:01
     |██████████████████████████████▉ | 153 kB 73.6 MB/s eta 0:00:01
     |████████████████████████████████| 159 kB 73.6 MB/s 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>?25hCollecting yarl&lt;2.0,&gt;=1.0
  Downloading yarl-1.6.3-cp38-cp38-manylinux2014_x86_64.whl (324 kB)
?25l
     |█                               | 10 kB 38.7 MB/s eta 0:00:01
     |██                              | 20 kB 41.8 MB/s eta 0:00:01
     |███                             | 30 kB 51.8 MB/s eta 0:00:01
     |████                            | 40 kB 59.6 MB/s eta 0:00:01
     |█████                           | 51 kB 65.2 MB/s eta 0:00:01
     |██████                          | 61 kB 70.4 MB/s eta 0:00:01
     |███████                         | 71 kB 45.0 MB/s eta 0:00:01
     |████████                        | 81 kB 41.7 MB/s eta 0:00:01
     |█████████                       | 92 kB 43.5 MB/s eta 0:00:01
     |██████████                      | 102 kB 41.2 MB/s eta 0:00:01
     |███████████▏                    | 112 kB 41.2 MB/s eta 0:00:01
     |████████████▏                   | 122 kB 41.2 MB/s eta 0:00:01
     |█████████████▏                  | 133 kB 41.2 MB/s eta 0:00:01
     |██████████████▏                 | 143 kB 41.2 MB/s eta 0:00:01
     |███████████████▏                | 153 kB 41.2 MB/s eta 0:00:01
     |████████████████▏               | 163 kB 41.2 MB/s eta 0:00:01
     |█████████████████▏              | 174 kB 41.2 MB/s eta 0:00:01
     |██████████████████▏             | 184 kB 41.2 MB/s eta 0:00:01
     |███████████████████▏            | 194 kB 41.2 MB/s eta 0:00:01
     |████████████████████▏           | 204 kB 41.2 MB/s eta 0:00:01
     |█████████████████████▏          | 215 kB 41.2 MB/s eta 0:00:01
     |██████████████████████▎         | 225 kB 41.2 MB/s eta 0:00:01
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     |███████████████████████▎        | 235 kB 41.2 MB/s eta 0:00:01
     |████████████████████████▎       | 245 kB 41.2 MB/s eta 0:00:01
     |█████████████████████████▎      | 256 kB 41.2 MB/s eta 0:00:01
     |██████████████████████████▎     | 266 kB 41.2 MB/s eta 0:00:01
     |███████████████████████████▎    | 276 kB 41.2 MB/s eta 0:00:01
     |████████████████████████████▎   | 286 kB 41.2 MB/s eta 0:00:01
     |█████████████████████████████▎  | 296 kB 41.2 MB/s eta 0:00:01
     |██████████████████████████████▎ | 307 kB 41.2 MB/s eta 0:00:01
     |███████████████████████████████▎| 317 kB 41.2 MB/s eta 0:00:01
     |████████████████████████████████| 324 kB 41.2 MB/s 
?25hCollecting async-timeout&lt;4.0,&gt;=3.0
  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)
Requirement already satisfied: attrs&gt;=17.3.0 in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from aiohttp-&gt;alpha_vantage) (20.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting typing-extensions&gt;=3.6.5
  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)
Requirement already satisfied: chardet&lt;5.0,&gt;=2.0 in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from aiohttp-&gt;alpha_vantage) (4.0.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: idna&gt;=2.0 in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;alpha_vantage) (2.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from requests-&gt;alpha_vantage) (2021.5.30)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.8.10/x64/lib/python3.8/site-packages (from requests-&gt;alpha_vantage) (1.26.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: multidict, yarl, typing-extensions, async-timeout, aiohttp, alpha-vantage
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully installed aiohttp-3.7.4.post0 alpha-vantage-2.3.1 async-timeout-3.0.1 multidict-5.1.0 typing-extensions-3.10.0.0 yarl-1.6.3
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fetch_data</span><span class="p">(</span><span class="n">symbol_</span><span class="p">):</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">TimeSeries</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;Y9RIDT1TH9HU3IB8&#39;</span><span class="p">,</span><span class="n">output_format</span><span class="o">=</span><span class="s1">&#39;pandas&#39;</span><span class="p">)</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">meta_data</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">get_intraday</span><span class="p">(</span><span class="n">symbol</span><span class="o">=</span><span class="n">symbol_</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="s1">&#39;1min&#39;</span><span class="p">,</span> <span class="n">outputsize</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaler_closep</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">13</span><span class="o">-</span><span class="mi">07538</span><span class="n">f58a6d6</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">scaler_closep</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;MinMaxScaler&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalize_data</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">scaler_closep</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">predicted_stock_price</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predicted_stock_price</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Predicted Price&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Close Price Prediction&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;DateTime&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Close Price&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">alpha_vantage.timeseries</span> <span class="kn">import</span> <span class="n">TimeSeries</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">preds</span><span class="o">=</span><span class="p">[]</span>


<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">df_ibm</span> <span class="o">=</span> <span class="n">fetch_data</span><span class="p">(</span><span class="s2">&quot;IBM&quot;</span><span class="p">)</span>
    <span class="n">data_spi</span> <span class="o">=</span> <span class="n">fetch_data</span><span class="p">(</span><span class="s2">&quot;IVE&quot;</span><span class="p">)</span>
    <span class="n">df_spi</span> <span class="o">=</span> <span class="n">data_spi</span><span class="p">[[</span><span class="s1">&#39;1. open&#39;</span><span class="p">,</span> <span class="s1">&#39;3. low&#39;</span><span class="p">,</span> <span class="s1">&#39;2. high&#39;</span><span class="p">,</span> <span class="s1">&#39;4. close&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_ibm</span><span class="p">,</span> <span class="n">df_spi</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">join_axes</span><span class="o">=</span><span class="p">[</span><span class="n">df_ibm</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>
    <span class="n">df_concat</span> <span class="o">=</span> <span class="n">df_concat</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
    <span class="n">df_concat</span> <span class="o">=</span> <span class="n">df_concat</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">60</span><span class="p">:,:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">normalize_data</span><span class="p">(</span><span class="n">df_concat</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">multi_head</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">pred_transf</span> <span class="o">=</span> <span class="n">scaler_closep</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_transf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="n">clear_output</span><span class="p">()</span>
    <span class="n">plot_data</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="c1"># runs for 4 hours </span>
    <span class="k">if</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">14400</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">16</span><span class="o">-</span><span class="n">c65e2f6fcd10</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="n">data_spi</span> <span class="o">=</span> <span class="n">fetch_data</span><span class="p">(</span><span class="s2">&quot;IVE&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>     <span class="n">df_spi</span> <span class="o">=</span> <span class="n">data_spi</span><span class="p">[[</span><span class="s1">&#39;1. open&#39;</span><span class="p">,</span> <span class="s1">&#39;3. low&#39;</span><span class="p">,</span> <span class="s1">&#39;2. high&#39;</span><span class="p">,</span> <span class="s1">&#39;4. close&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">14</span>     <span class="n">df_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_ibm</span><span class="p">,</span> <span class="n">df_spi</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">join_axes</span><span class="o">=</span><span class="p">[</span><span class="n">df_ibm</span><span class="o">.</span><span class="n">index</span><span class="p">])</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="n">df_concat</span> <span class="o">=</span> <span class="n">df_concat</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>     <span class="n">df_concat</span> <span class="o">=</span> <span class="n">df_concat</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">60</span><span class="p">:,:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="ne">TypeError</span>: concat() got an unexpected keyword argument &#39;join_axes&#39;
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./pystocks/stocks/methods"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Christian Kruse<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>